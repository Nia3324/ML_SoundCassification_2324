{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extration for the Convolutional Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries and setting some variables that we will be wanting to use for all the features' extraction processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedures to save and load extracted data from and to the disk\n",
    "\n",
    "Throughout this notebook, we will be using the following procedures to save steps of our processed data into the disk, such that we can load it later if we need to.\n",
    "\n",
    "These functions take advantage of Python's library _Pickle_, which allow us to save the content of our variables in binary files of extension _.pkl_, and to load them with the structure that it was saved from (dictionary, NumPy array, class object, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(data, path):\n",
    "    with open(path, \"wb\") as saved_data:\n",
    "        pickle.dump(data, saved_data)\n",
    "    saved_data.close()\n",
    "\n",
    "def load_pkl(path):\n",
    "    to_return = None\n",
    "    with open(path, \"rb\") as loaded_data:\n",
    "        to_return = pickle.load(loaded_data)\n",
    "    loaded_data.close()\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data's Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0       100032-3-0-0.wav  100032    0.000000    0.317551         1     5   \n",
       "1     100263-2-0-117.wav  100263   58.500000   62.500000         1     5   \n",
       "2     100263-2-0-121.wav  100263   60.500000   64.500000         1     5   \n",
       "3     100263-2-0-126.wav  100263   63.000000   67.000000         1     5   \n",
       "4     100263-2-0-137.wav  100263   68.500000   72.500000         1     5   \n",
       "...                  ...     ...         ...         ...       ...   ...   \n",
       "8727     99812-1-2-0.wav   99812  159.522205  163.522205         2     7   \n",
       "8728     99812-1-3-0.wav   99812  181.142431  183.284976         2     7   \n",
       "8729     99812-1-4-0.wav   99812  242.691902  246.197885         2     7   \n",
       "8730     99812-1-5-0.wav   99812  253.209850  255.741948         2     7   \n",
       "8731     99812-1-6-0.wav   99812  332.289233  334.821332         2     7   \n",
       "\n",
       "      classID             class  \n",
       "0           3          dog_bark  \n",
       "1           2  children_playing  \n",
       "2           2  children_playing  \n",
       "3           2  children_playing  \n",
       "4           2  children_playing  \n",
       "...       ...               ...  \n",
       "8727        1          car_horn  \n",
       "8728        1          car_horn  \n",
       "8729        1          car_horn  \n",
       "8730        1          car_horn  \n",
       "8731        1          car_horn  \n",
       "\n",
       "[8732 rows x 8 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info = pd.read_csv(\"./UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
    "data_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling and Zero Padding\n",
    "\n",
    "Firstly, we will resample all of our audio raw data such that the resulting data has a sample rate of 44.1 KHz. We will also zero-pad it such that all data points represent audio with 4 seconds of duration.\n",
    "\n",
    "All data will be saved seperately by fold.\n",
    "\n",
    "We will also save the corresponding .wav file name such that we can correctly obtain its fold and classification in the dataset metadata CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS_PATH = \"UrbanSound8K/audio/\"\n",
    "DURATION = 4 # 4 seconds for each audio file\n",
    "SAMPLE_RATE = 44100\n",
    "HOP_LENGTH = round(SAMPLE_RATE * 0.0125)\n",
    "WIN_LENGTH = round(SAMPLE_RATE * 0.023)\n",
    "N_FFT = 2**10\n",
    "TIME_SIZE = 4*SAMPLE_RATE//HOP_LENGTH+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(audio_file_path):\n",
    "    signal, sample_rate = librosa.load(audio_file_path, sr=None)\n",
    "    # resample the sample rate to the target value of SR\n",
    "    signal = librosa.resample(signal, orig_sr=sample_rate, target_sr=SAMPLE_RATE)\n",
    "    # zero padding\n",
    "    if len(signal) < DURATION*SAMPLE_RATE:\n",
    "        signal = np.concatenate([\n",
    "            signal,\n",
    "            np.zeros(shape=(DURATION*SAMPLE_RATE - len(signal), ))\n",
    "        ])\n",
    "    elif len(signal) > DURATION*SAMPLE_RATE:\n",
    "        signal = signal[:DURATION*SAMPLE_RATE]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold10\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n"
     ]
    }
   ],
   "source": [
    "folds = [fold for fold in os.listdir(FOLDS_PATH) if \"fold\" in fold]\n",
    "for fold in folds:\n",
    "    print(fold)\n",
    "    df_data = []\n",
    "    audio_files = librosa.util.find_files(FOLDS_PATH+\"/\"+fold)\n",
    "    for audio_file_path in audio_files:\n",
    "        audio_file = audio_file_path.split(\"\\\\\")[-1]\n",
    "        df_data.append({'id': audio_file, 'zero_padded_data': zero_pad(audio_file_path)})\n",
    "    df = pd.DataFrame(data=df_data, columns=['id', 'zero_padded_data'])\n",
    "    save_pkl(df, f\"features/zero_pad/{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of the 2D features\n",
    "\n",
    "For this task, we will be taking advange of Librosa's library capabilities and extract the following 2D features from the .wav files availavle in the _UrbanSound8K_ dataset:\n",
    "- Chromagram\n",
    "- Mel-scaled Spectogram\n",
    "- Short-time Fourier transform Tempogram\n",
    "\n",
    "The following functions allow us to extract, in order, the beforehand mentioned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chromagram(audio_data):\n",
    "    N_CHROMA = 12\n",
    "    return librosa.feature.chroma_stft(y=audio_data, n_chroma=N_CHROMA, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spectogram(audio_data):\n",
    "    return librosa.feature.melspectrogram(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_tempogram(audio_data):\n",
    "    return np.abs(librosa.feature.fourier_tempogram(y=audio_data, sr=SAMPLE_RATE, hop_length=HOP_LENGTH, win_length=WIN_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we extract the features and save the obtained data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1014 is too large for input signal of length=321\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df = load_pkl(f\"features/zero_pad/fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    df_extracted_data = []\n",
    "    for i in range(fold_df.shape[0]):\n",
    "        extracted_data = {\n",
    "            'id': fold_df.iloc[i,0],\n",
    "            'chromagram': chromagram(fold_df.iloc[i,1]),\n",
    "            'mel_spectogram': mel_spectogram(fold_df.iloc[i,1]),\n",
    "            'fourier_tempogram': fourier_tempogram(fold_df.iloc[i,1])\n",
    "        }\n",
    "        df_extracted_data.append(extracted_data)\n",
    "    df = pd.DataFrame(data=df_extracted_data, columns=['id', 'chromagram', 'mel_spectogram', 'fourier_tempogram'])\n",
    "    save_pkl(df, f\"features/extracted_2d/extracted_2d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del df_extracted_data\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of the 1D features\n",
    "\n",
    "We will be taking advange of Librosa's library capabilities once again to extract some 1D features from the .wav files. Here are presented the 1D features to be extracted:\n",
    "- Spectral Centroid\n",
    "- Spectral Bandwidth\n",
    "- Spectral Flatness\n",
    "- Spectral Rolloff\n",
    "\n",
    "The following functions allow us to extract, in order, the beforehand mentioned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_centroid(audio_data):\n",
    "    return librosa.feature.spectral_centroid(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_bandwidth(audio_data):\n",
    "    return librosa.feature.spectral_bandwidth(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_flatness(audio_data):\n",
    "    return librosa.feature.spectral_flatness(y=audio_data, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_rolloff(audio_data):\n",
    "    return librosa.feature.spectral_rolloff(y=audio_data, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, win_length=WIN_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n",
      "fold10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df = load_pkl(f\"features/zero_pad/fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    df_extracted_data = []\n",
    "    for i in range(fold_df.shape[0]):\n",
    "        extracted_data = {\n",
    "            'id': fold_df.iloc[i,0],\n",
    "            'spectral_centroid': spectral_centroid(fold_df.iloc[i,1]),\n",
    "            'spectral_bandwidth': spectral_bandwidth(fold_df.iloc[i,1]),\n",
    "            'spectral_flatness': spectral_flatness(fold_df.iloc[i,1]),\n",
    "            'spectral_rolloff': spectral_rolloff(fold_df.iloc[i,1])\n",
    "        }\n",
    "        df_extracted_data.append(extracted_data)\n",
    "    df = pd.DataFrame(data=df_extracted_data, columns=['id', 'spectral_centroid', 'spectral_bandwidth', 'spectral_flatness', 'spectral_rolloff'])\n",
    "    save_pkl(df, f\"features/extracted_1d/extracted_1d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del df_extracted_data\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization the data\n",
    "\n",
    "As a last step of our Data Pre-Processing and Feature Extraction phases for our CNN model, we are going to normalize all values extracted, feature by feature, using the Min-Max scalling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D\n",
      "fold1\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n",
      "fold10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"2D\")\n",
    "for i in range(1,10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df: pd.DataFrame = load_pkl(f\"features/extracted_2d/extracted_2d_fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    cols = ['chromagram', 'mel_spectogram', 'fourier_tempogram']\n",
    "    for col in cols:\n",
    "        stacked_values = np.vstack(fold_df[col])\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_values = scaler.fit_transform(stacked_values)\n",
    "        original_shapes = [value.shape for value in fold_df[col]]\n",
    "        normalized_arrays = [normalized_values[i:i+len(value)].reshape(shape) for i, (value, shape) in enumerate(zip(fold_df[col], original_shapes))]\n",
    "        # update the dataframe column with the normalized values\n",
    "        fold_df[col] = normalized_arrays\n",
    "    fold_df.rename(columns={'id':'slice_file_name'}, inplace=True)\n",
    "    save_pkl(fold_df, f\"features/normalized_feats/norm_feats_2d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del stacked_values\n",
    "    del normalized_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D\n",
      "fold1\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n",
      "fold10\n"
     ]
    }
   ],
   "source": [
    "print(\"1D\")\n",
    "for i in range(1,10+1):\n",
    "    fold = f\"fold{i}\"\n",
    "    fold_df = load_pkl(f\"features/extracted_1d/extracted_1d_fold{i}_csv.pkl\")\n",
    "    print(fold)\n",
    "    cols = ['spectral_centroid', 'spectral_bandwidth', 'spectral_flatness', 'spectral_rolloff']\n",
    "    for col in cols:\n",
    "        stacked_values = np.vstack(fold_df[col])\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_values = scaler.fit_transform(stacked_values)\n",
    "        original_shapes = [value.shape for value in fold_df[col]]\n",
    "        normalized_arrays = [normalized_values[i:i+len(value)].reshape(shape) for i, (value, shape) in enumerate(zip(fold_df[col], original_shapes))]\n",
    "        # update the dataframe column with the normalized values\n",
    "        fold_df[col] = normalized_arrays\n",
    "    fold_df.rename(columns={'id':'slice_file_name'}, inplace=True)\n",
    "    save_pkl(fold_df, f\"features/normalized_feats/norm_feats_1d_{fold}_csv.pkl\")\n",
    "    # memory management\n",
    "    del fold_df\n",
    "    del stacked_values\n",
    "    del normalized_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the final DataFrames\n",
    "\n",
    "In this set, we merge all the 2D and 1D features we collected into a single dataframe.\n",
    "\n",
    "We also One-Hot encode the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1\n",
      "fold2\n",
      "fold3\n",
      "fold4\n",
      "fold5\n",
      "fold6\n",
      "fold7\n",
      "fold8\n",
      "fold9\n",
      "fold10\n"
     ]
    }
   ],
   "source": [
    "# build the folds dataframes for the cnn training\n",
    "\n",
    "target_df = pd.read_csv(\"./UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
    "target_df = target_df[['slice_file_name','classID']]\n",
    "# one hot encode the target class id\n",
    "ohe_targets = np.zeros(shape=(target_df['classID'].size, target_df['classID'].max()+1))\n",
    "ohe_targets[np.arange(target_df['classID'].size), target_df['classID'].to_numpy(dtype=np.int16)] = 1\n",
    "target_df['classID'] = ohe_targets.tolist()\n",
    "target_df['classID'].apply(np.array)\n",
    "\n",
    "# build the folds dataframes\n",
    "for i in range(1, 10+1):\n",
    "    print(f\"fold{i}\")\n",
    "    feat_2d_df = load_pkl(f\"./features/normalized_feats/norm_feats_2d_fold{i}_csv.pkl\")\n",
    "    feat_1d_df = load_pkl(f\"./features/normalized_feats/norm_feats_1d_fold{i}_csv.pkl\")\n",
    "    fold_df = pd.merge(left=feat_2d_df, right=feat_1d_df, on=\"slice_file_name\")\n",
    "    fold_df = pd.merge(left=fold_df, right=target_df, on=\"slice_file_name\")\n",
    "    save_pkl(fold_df, f\"./cnn_folds_dataframes/fold{i}_df.pkl\")\n",
    "    # memory management\n",
    "    del feat_2d_df\n",
    "    del feat_1d_df\n",
    "    del fold_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
