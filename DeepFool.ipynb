{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INKkcfJ_rT9F"
      },
      "source": [
        "# Robustness of the obtained models to Adversarial Examples using the DeepFool algorithm for multi-class problems\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This Jupyter notebook was created by Ant√≥nia Brito, Ant√≥nio Cardoso and Pedro Sousa for the Machine Learning II (CC3043) course at University of Porto. It serves as a practical execution of the _DeepFool_ algorithm as an evaluation strategy for the robustness of the obtained models against adversarial examples.\n",
        "\n",
        "## Authorship\n",
        "\n",
        "- **Author:** Ant√≥nia Brito, Ant√≥nio Cardoso, Pedro Sousa\n",
        "- **University:** Faculty of Science from University of Porto\n",
        "- **Course:** Machine Learning II (CC3043)\n",
        "- **Date:** 05/12/2023\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvhPIwoNf56"
      },
      "source": [
        "## The *DeepFool* Algorithm\n",
        "\n",
        "Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi and Pascal Frossard published a paper proposing an algorithm entitled DeepFool to evaluate with a simple and accurate methodology the robustness of a classifier against adversarial examples ([link to the publication in PDF format](https://openaccess.thecvf.com/content_cvpr_2016/papers/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.pdf)).\n",
        "\n",
        "For a given classifier and example, the algorithm is set to compute the minimal perturbation that is sufficient to change the estimated label. For the remainder of the section, the following notation will be used:\n",
        "\n",
        "- $f$: a given classifier that outputs a vector with the probability distribution for the classification associated with its probability index.\n",
        "\n",
        "- $x$: a given example.\n",
        "\n",
        "- $X$: the domain of the examples.\n",
        "\n",
        "- $T$: the domain of test examples available.\n",
        "\n",
        "- $k$: a possible classification of the considered problem. Thus, the probability of the classification of an example $x$ to be $k$ is $f_k(x)$.\n",
        "\n",
        "- $\\hat{k}(x)$: the estimated classification of a given example. It is noted that $\\hat{k}(x) = argmax_k( f_k(x) )$.\n",
        "\n",
        "- $\\hat{r}(x)$: the minimal perturbation for which $\\hat{k}(x) \\ne \\hat{k}(x+\\hat{r}(x))$.\n",
        "\n",
        "The DeepFool algorithm only outputs the value of the minimal perturbation $\\hat{r}(x)$ of a given example $x$. The following pseudocode represents the DeepFool algorithm:\n",
        "\n",
        "![DeepFool Algorithm](./deepfool_alg.png)\n",
        "\n",
        "Finally, the proposed formal definition for the robustness to adversarial examples of a given classifier is the expected value over the domain of examples for the norm of the minimal perturbation for an example divided by the norm of that same example. For practical purposes, the aforementioned expected value is approximated to the mean value for all examples in the available test domain of the classifier:\n",
        "\n",
        "$\\rho_{adv}(f) = ùîº_X \\frac{||\\hat{r}(x)||_2}{||x||_2} ‚âà \\frac{1}{|T|} ‚àë_{x\\in T} \\frac{||\\hat{r}(x)||_2}{||x||_2}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt5RRpvEyPCg",
        "outputId": "f545157b-febe-402a-93a1-62ddcc983136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# this notebook was entirely run using Google Colab\n",
        "# to access the models' data through a cloud drive, this initial code block was needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZwHyqxcrT9G"
      },
      "source": [
        "### Implementation of the DeepFool algorithm for multi-class problems on a given model and input example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "07kwO4K-rT9H"
      },
      "outputs": [],
      "source": [
        "# import of relevant libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, regularizers, optimizers\n",
        "from tensorflow.python.client import device_lib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import librosa\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f-FFqzEurT9J"
      },
      "outputs": [],
      "source": [
        "# function that calculates the gradient of the k-th element in the model output, given a input x, with respect to the input x\n",
        "def get_gradient(model, x, k):\n",
        "\n",
        "    # compute the k-th value of the model output using x as the input under the watch of tensorflow's GradientTape\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        inputs = [tf.cast(input_value, dtype=tf.float64) for input_value in x]\n",
        "        for input_value in inputs:\n",
        "            tape.watch(input_value)\n",
        "        results = model(inputs)\n",
        "        results_k = results[0,k]\n",
        "\n",
        "    # obtain the gradient of the k-th element in the model output w.r.t. the input\n",
        "    gradients = tape.gradient(results_k, inputs)\n",
        "    del tape\n",
        "    return [grad.numpy() for grad in gradients], results\n",
        "\n",
        "\n",
        "# function that implements the DeepFool algorithm\n",
        "# model: the model to be used in the algorithm\n",
        "# x0: the initial input without any perturbation\n",
        "# eta: an overshoot value to be multiplied with each iteration's perturbation\n",
        "# max_iter: maximum nummber of iterations  the algorithm is allowed to execute\n",
        "def deepfool(model, x0, eta=0.01, max_iter=20):\n",
        "\n",
        "    # obtain the initial estimated label\n",
        "    f_x0 = model(x0).numpy().flatten()\n",
        "    label_x0 = f_x0.argsort()[::-1][0]\n",
        "\n",
        "    loop_i = 0\n",
        "    xi = deepcopy(x0)\n",
        "    label_xi = label_x0\n",
        "    r = []\n",
        "\n",
        "    # main loop\n",
        "    while label_xi == label_x0 and loop_i < max_iter:\n",
        "        w_l = [np.zeros(x_input.shape) for x_input in x0]\n",
        "        f_l = 0\n",
        "        fk_wk_min = np.inf\n",
        "        grad_f_label_x0_on_xi, f_xi = get_gradient(model, xi, label_x0)\n",
        "\n",
        "        for k in range(10): # k = 0, ..., 9 (possible classes in the problem considered for this project)\n",
        "            if (k == label_x0):\n",
        "                continue\n",
        "            grad_f_k_on_xi, f_xi = get_gradient(model, xi, k)\n",
        "            w_k = [g_f_k - g_f_label for g_f_k, g_f_label in zip(grad_f_k_on_xi, grad_f_label_x0_on_xi)]\n",
        "            w_k_norm = np.sqrt(np.sum(np.fromiter([np.linalg.norm(w_k_input)**2 for w_k_input in w_k], dtype=np.float32)))\n",
        "            f_k = f_xi[0,k] - f_xi[0,label_x0]\n",
        "            fk_wk = np.linalg.norm(f_k) / (w_k_norm + 1e-3)\n",
        "            if fk_wk < fk_wk_min:\n",
        "                w_l, f_l = w_k, f_k\n",
        "        \n",
        "        w_l_squared_norm = np.sum(np.fromiter([np.linalg.norm(w_l_input)**2 for w_l_input in w_l], dtype=np.float32))\n",
        "        f_l_norm = np.linalg.norm(f_l)\n",
        "        ri_const = f_l_norm / (w_l_squared_norm + 1e-3)\n",
        "        ri = [ri_const * w_l_input for w_l_input in w_l]\n",
        "        r.append(ri)\n",
        "        xi_new = [xi_item + (1+eta)*ri_item for xi_item, ri_item in zip(xi, ri)]\n",
        "        xi = xi_new\n",
        "        label_xi = model(xi).numpy().flatten().argsort()[::-1][0]\n",
        "        loop_i += 1\n",
        "\n",
        "    # main loop finished\n",
        "    r_sum = [np.zeros(x_input.shape) for x_input in x0]\n",
        "    for i in range(len(x0)):\n",
        "        for r_i in r:\n",
        "            r_sum[i] += r_i[i][0]\n",
        "\n",
        "    # return the value of r(x), number of iterations performed, and the new label obtained by adding the perturbation to the input\n",
        "    return r_sum, loop_i, label_xi\n",
        "\n",
        "\n",
        "# function to calculate the value of ||r(x)|| / ||x||\n",
        "def example_robustness(x, r):\n",
        "    r_norm = np.sqrt(np.sum(np.fromiter([np.linalg.norm(r_input)**2 for r_input in r], dtype=np.float32)))\n",
        "    x_norm = np.sqrt(np.sum(np.fromiter([np.linalg.norm(x_input)**2 for x_input in x], dtype=np.float32)))\n",
        "    return r_norm / x_norm\n",
        "\n",
        "\n",
        "# function to return the robustness of a model\n",
        "def model_robustness(example_robustness_list):\n",
        "    mean = np.mean(np.array(example_robustness_list))\n",
        "    std = np.std(np.array(example_robustness_list))\n",
        "    return mean, std\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujbNUcL2jCjr"
      },
      "source": [
        "### Saving and Loading functions\n",
        "\n",
        "These functions utilize Python's _Pickle_ library. They allow to save and load the content of any Python variable, in binary, maintaining the structure of its data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "feMDwQpJrT9K"
      },
      "outputs": [],
      "source": [
        "def save_pkl(data, path):\n",
        "    with open(path, \"wb\") as saved_data:\n",
        "        pickle.dump(data, saved_data)\n",
        "    saved_data.close()\n",
        "\n",
        "def load_pkl(path):\n",
        "    to_return = None\n",
        "    with open(path, \"rb\") as loaded_data:\n",
        "        to_return = pickle.load(loaded_data)\n",
        "    loaded_data.close()\n",
        "    return to_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUDKEZbQjZcG"
      },
      "source": [
        "## Methodology for the Empirical Experience using DeepFool\n",
        "\n",
        "As stated before, the robustness for a classifier is defined, in practice, as the mean value for the norm of the minimal perturbation for an example divided by its norm.\n",
        "\n",
        "\n",
        "Given that the models constructed in this project were empirically evaluated using a 10-fold cross validation, it is deemed necessary to obtain the robustness for each of the models trained in the cross validation process, both for the CNN and the RNN models.\n",
        "\n",
        "Hence, at each iteration, the data to be used to test the robustness to adversarial examples of the current model will be the same test data used to compute the cross validation metrics in the notebooks *CNN.ipynb* and *LSTM.ipynb*.\n",
        "\n",
        "The final results to be present for each of the model architectures will be the mean value and standard deviation of the obtained results for each of the cross validation test datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8h15jCWbC3f"
      },
      "source": [
        "## Running the DeepFool algorithm on the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJRo7XMfrT9P"
      },
      "outputs": [],
      "source": [
        "# loading the data to be fed into the CNN model\n",
        "df_data = load_pkl(\"/content/drive/MyDrive/Colab Notebooks/urbansound8k_cnn.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8AZC2tsrT9Q"
      },
      "outputs": [],
      "source": [
        "SAMPLE_RATE = 22050\n",
        "HOP_LENGTH = round(SAMPLE_RATE * 0.0125)\n",
        "TIME_SIZE = 4*SAMPLE_RATE//HOP_LENGTH+1\n",
        "\n",
        "for f in range(1, 10+1):\n",
        "\n",
        "    # this list will hold the values ||r(x)|| / ||x|| initially mentioned on the notebook \n",
        "    robustness_values_cnn_fold = []\n",
        "\n",
        "    # utilize only the data of the f-th fold\n",
        "    X_fold = df_data[df_data['fold'] == f\"fold{f}\"]\n",
        "\n",
        "    # separate the data for each input stream of the CNN model (mel-scaled spectrograms, chromagrams, 1D features - stacked)\n",
        "    # explicit casts to assure type integrity of the data before being passed to the model\n",
        "    X_mel = np.asarray(X_fold[\"mel_spec\"].to_list()).astype(np.float32)\n",
        "    X_chroma = np.asarray(X_fold[\"chroma\"].to_list()).astype(np.float32)\n",
        "    centroid = np.asarray(tuple(X_fold[\"spectral_centroid\"].to_list())).astype(np.float32)\n",
        "    bandwidth = np.asarray(tuple(X_fold[\"spectral_bandwidth\"].to_list())).astype(np.float32)\n",
        "    flatness = np.asarray(tuple(X_fold[\"spectral_flatness\"].to_list())).astype(np.float32)\n",
        "    rolloff = np.asarray(tuple(X_fold[\"spectral_rolloff\"].to_list())).astype(np.float32)\n",
        "    X_1d = np.stack([centroid,bandwidth,flatness,rolloff], axis=-1)\n",
        "    X_1d = X_1d.reshape(-1, TIME_SIZE, 4)\n",
        "\n",
        "    # load the model from the performance evaluation cross validation run that used the f-th fold as the test fold\n",
        "    # the compile keyword argument was set to false such that the model can be explicitly re-compiled using the compile settings defined on CNN.ipynb\n",
        "    fold_model_cnn = keras.models.load_model(f\"/content/drive/MyDrive/Colab Notebooks/CNN Models/cnn_model{f}.h5\", compile=False)\n",
        "    fold_model_cnn.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # begin the run of each example in the f-th fold and the corresponding model on the DeepFool algorithm\n",
        "    for i in range(len(X_fold)):\n",
        "\n",
        "        # prepare the input for the implemented DeepFool function\n",
        "        example_input = [np.array([X_mel[i]]), np.array([X_chroma[i]]), np.array([X_1d[i]])]\n",
        "\n",
        "        # run DeepFool\n",
        "        perturbation, iters, fool_label = deepfool(fold_model_cnn, example_input)\n",
        "\n",
        "        # save the ||r(x)|| / ||x|| value into the list defined in the beginning of the \"fold\" for loop\n",
        "        robustness_values_cnn_fold.append(example_robustness(example_input, perturbation))\n",
        "\n",
        "    # to save the results of each fold\n",
        "    save_pkl(robustness_values_cnn_fold, f\"/content/drive/MyDrive/Colab Notebooks/robustness_values_cnn_fold{f}.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUvWQrPgrT9R",
        "outputId": "59f7cbc7-e86f-416f-f1ac-39bf7313e1f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 - The CNN model has a robustness of  0.0000998 +/-  0.0001057.\n",
            "Fold 2 - The CNN model has a robustness of  0.0000744 +/-  0.0000929.\n",
            "Fold 3 - The CNN model has a robustness of  0.0001274 +/-  0.0001670.\n",
            "Fold 4 - The CNN model has a robustness of  0.0000907 +/-  0.0001367.\n",
            "Fold 5 - The CNN model has a robustness of  0.0001199 +/-  0.0001449.\n",
            "Fold 6 - The CNN model has a robustness of  0.0000607 +/-  0.0000818.\n",
            "Fold 7 - The CNN model has a robustness of  0.0000913 +/-  0.0000947.\n",
            "Fold 8 - The CNN model has a robustness of  0.0001069 +/-  0.0001206.\n",
            "Fold 9 - The CNN model has a robustness of  0.0001230 +/-  0.0001500.\n",
            "Fold 10 - The CNN model has a robustness of  0.0000922 +/-  0.0000921.\n"
          ]
        }
      ],
      "source": [
        "# check each folds' models results\n",
        "for f in range(1, 10+1):\n",
        "    robustness_values_cnn_fold = load_pkl(f\"/content/drive/MyDrive/Colab Notebooks/robustness_values_cnn_fold{f}.pkl\")\n",
        "    mean_robustness_cnn, std_robustness_cnn = model_robustness(robustness_values_cnn_fold)\n",
        "    print(f\"Fold {f} - The CNN model has a robustness of {mean_robustness_cnn: .7f} +/- {std_robustness_cnn: .7f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDtFvHOgjRGH"
      },
      "source": [
        "The results for the various folds' models indicate that they are not very robust to adversarial examples, as the norm of the minimal perturbation to alter the models' predictions is very small relatively to the corresponding input's norm (about 0.00607% to 0.01274% of the original input's norm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZsKjr5vbI38"
      },
      "source": [
        "## Running the DeepFool algorithm for the RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aHlUFDHovY1l"
      },
      "outputs": [],
      "source": [
        "# loading the data to be fed into the RNN model\n",
        "df_data = load_pkl(\"/content/drive/MyDrive/Colab Notebooks/urbansound8k_rnn.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx1wYYT5arAZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "for f in range(1, 10+1):\n",
        "\n",
        "    # this list will hold the values ||r(x)|| / ||x|| initially mentioned on the notebook \n",
        "    robustness_values_rnn_fold = []\n",
        "\n",
        "    # utilize only the data of the f-th fold\n",
        "    X_fold = df_data[df_data['fold'] == f\"fold{f}\"]\n",
        "\n",
        "    # the data to be inputed into the RNN model (spectogram)\n",
        "    # explicit cast to assure type integrity of the data before being passed to the model\n",
        "    X_spec = np.asarray(X_fold[\"spec\"].to_list()).astype(np.float32)\n",
        "\n",
        "    # load the model from the performance evaluation cross validation run that used the f-th fold as the test fold\n",
        "    # the compile keyword argument was set to false such that the model can be explicitly re-compiled using the compile settings defined on LSTM.ipynb\n",
        "    fold_model_rnn = keras.models.load_model(f\"/content/drive/MyDrive/Colab Notebooks/RNN Models/rnn_model{f}.h5\", compile=False)\n",
        "    fold_model_rnn.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # begin the run of each example in the f-th fold and the corresponding model on the DeepFool algorithm\n",
        "    for i in range(len(X_fold)):\n",
        "\n",
        "        # prepare the input for the implemented DeepFool function\n",
        "        example_input = [np.array([X_spec[i]])]\n",
        "\n",
        "        # run DeepFool\n",
        "        # eta keyword argument was set to 10^6 due to the extremely small order of magnitude of each iteration's perturbation (between 10^-8 and 10^-5)\n",
        "        perturbation, iters, fool_label = deepfool(fold_model_rnn, example_input, eta=1e6)\n",
        "\n",
        "        # save the ||r(x)|| / ||x|| value into the list defined in the beginning of the \"fold\" for loop\n",
        "        robustness_values_rnn_fold.append(example_robustness(example_input, perturbation))\n",
        "\n",
        "    # to save the results of each fold\n",
        "    save_pkl(robustness_values_rnn_fold, f\"/content/drive/MyDrive/Colab Notebooks/robustness_values_rnn_fold{f}.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urnJdeq7viJQ",
        "outputId": "4bb1d9db-c020-41db-ebd8-0fcc87d044ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 - The RNN model has a robustness of  0.0009903 +/-  0.0012117.\n",
            "Fold 2 - The RNN model has a robustness of  0.0010233 +/-  0.0011046.\n",
            "Fold 3 - The RNN model has a robustness of  0.0015006 +/-  0.0011319.\n",
            "Fold 4 - The RNN model has a robustness of  0.0012471 +/-  0.0010433.\n",
            "Fold 5 - The RNN model has a robustness of  0.0015296 +/-  0.0013027.\n",
            "Fold 6 - The RNN model has a robustness of  0.0007348 +/-  0.0010656.\n",
            "Fold 7 - The RNN model has a robustness of  0.0011942 +/-  0.0010320.\n",
            "Fold 8 - The RNN model has a robustness of  0.0013856 +/-  0.0013305.\n",
            "Fold 9 - The RNN model has a robustness of  0.0009796 +/-  0.0011695.\n",
            "Fold 10 - The RNN model has a robustness of  0.0008553 +/-  0.0008744.\n"
          ]
        }
      ],
      "source": [
        "# check each folds' models results\n",
        "for f in range(1, 10+1):\n",
        "    robustness_values_rnn_fold = load_pkl(f\"/content/drive/MyDrive/Colab Notebooks/robustness_values_rnn_fold{f}.pkl\")\n",
        "    mean_robustness_rnn, std_robustness_rnn = model_robustness(robustness_values_rnn_fold)\n",
        "    print(f\"Fold {f} - The RNN model has a robustness of {mean_robustness_rnn: .7f} +/- {std_robustness_rnn: .7f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw8LuTxeuU6S"
      },
      "source": [
        "The RNN results show some improvement compared to the CNN ones by a relative factor of approximately 10 times higher.\n",
        "\n",
        "However, the results show that the model robustness is considerably weak, as the magnitude of the minimal perturbation that changes the model prediction is quite small, ranging from 0.099% to 0.152% of the original input's magnitude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "The DeepFool algorithm has proven its intended utility case in this notenook, by allowing to evaluate how the composed models for this project react to adversarial examples and finding metrics for the robustness of these models in regard to their predictions stability.\n",
        "\n",
        "Unfortunately, the models presented a not-so-rich performance given the results computed above. However, one course of action to improve the robustness of these examples would be to use DeepFool as an auxiliar method to fine-tune the models' parameters such that their performances against adversarial inputs are more concise and stable.\n",
        "\n",
        "This experiment has widened the need to design and create models that perform better against perturbations, using the DeepFool algorithm as one of the benchmark algorithms to obtain metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivKIf_b3vcEK"
      },
      "source": [
        "## References\n",
        "\n",
        "- Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Polytechnique, E. and De Lausanne, F. (2016). DeepFool: a simple and accurate method to fool deep neural networks. [online] Available at: https://openaccess.thecvf.com/content_cvpr_2016/papers/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.pdf [Accessed 3 Dec. 2023].\n",
        "\n",
        "- Morgan, A. (2022). A Review of DeepFool: a simple and accurate method to fool deep neural networks. [online] Machine Intelligence and Deep Learning. Available at: https://medium.com/machine-intelligence-and-deep-learning-lab/a-review-of-deepfool-a-simple-and-accurate-method-to-fool-deep-neural-networks-b016fba9e48e#:~:text=DeepFool%20finds%20the%20minimal%20perturbations [Accessed 3 Dec. 2023].\n",
        "\n",
        "- TensorFlow. (2023). Introduction to gradients and automatic differentiation | TensorFlow Core. [online] Available at: https://www.tensorflow.org/guide/autodiff."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
